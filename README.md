# ğŸ§  DecentraMind MVP

A privacy-preserving decentralized AI system designed to demonstrate secure interaction between a user dApp and a local LLM inference node. This MVP encrypts all communication using modern cryptography and executes LLMs inside isolated containers to simulate privacy-first AI processing at the edge.

---

## ğŸ“¦ Project Structure

```

decentramind-mvp/
â”œâ”€â”€ llm-node/                  # Secure LLM inference node (FastAPI + Docker)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # Entry point (FastAPI server)
â”‚   â”‚   â”œâ”€â”€ model\_runner.py    # Model execution (LLM or dummy)
â”‚   â”‚   â”œâ”€â”€ crypto\_utils.py    # AES & Curve25519 decryption utilities
â”‚   â”‚   â””â”€â”€ config.py          # Constants (e.g., keys, model paths)
â”‚   â”œâ”€â”€ Dockerfile             # Containerized LLM runtime
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â””â”€â”€ README.md              # Node-specific instructions

â”œâ”€â”€ client-dapp/              # Frontend Web3 dApp (Next.js + Tailwind)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # Chat UI, input box, message list
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚       â”œâ”€â”€ crypto.ts      # Curve25519 + AES-GCM encryption (client â†’ node)
â”‚   â”‚       â””â”€â”€ decrypt.ts     # Decryption for LLM responses
â”‚   â”œâ”€â”€ public/                # Static assets
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ README.md              # Frontend-specific instructions

â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                  # You're here!

````

---

## ğŸš€ How It Works

1. User connects via MetaMask wallet in the dApp.
2. Message is encrypted using Curve25519 + AES-256-GCM.
3. Encrypted payload is sent via REST to a local or remote LLM node.
4. LLM Node decrypts payload, runs a model inside Docker sandbox, returns encrypted response.
5. Client decrypts and displays the output.

**âœ… Fully encrypted**, **â›“ï¸ On-chain identity (public key = wallet)**, **ğŸ§± Edge-first private inference.**

---

## ğŸ” Cryptography

- **Key Exchange:** X25519 (NaCl box sealing)
- **Symmetric Encryption:** AES-256-GCM
- **Transport:** REST (can be upgraded to HTTPS + gRPC)
- **Optional:** IPFS for encrypted chat log storage

---

## âš™ï¸ Setup Instructions

### 1. Clone Repository

```bash
git clone https://github.com/DecentraLandMind/decentramind-mvp.git
cd decentramind-mvp
````

### 2. Backend â€“ Secure LLM Node

```bash
cd llm-node
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload --port 9000
```

### 3. Frontend â€“ Web3 dApp

```bash
cd client-dapp
npm install
npm run dev
```

Open in browser: `http://localhost:3000`

---

## ğŸ§ª Testing Flow

1. Connect MetaMask
2. Write a message (e.g., â€œHello AIâ€)
3. Watch it get encrypted â†’ securely sent â†’ model replies back encrypted
4. Decrypt and display output in chat

---

## ğŸ§± Technologies Used

* ğŸ” **PyNaCl / AES** for secure payloads
* âš¡ **FastAPI** for inference node
* ğŸ§  **llama.cpp** or dummy model runner (Docker)
* ğŸ”— **MetaMask + Ethers.js** for auth
* ğŸ’¬ **Next.js + Tailwind CSS** frontend

---

## ğŸ“Œ Security Notes

* Keys are never stored or logged in plaintext.
* AES session keys are ephemeral per message.
* The model runs in an isolated Docker container (optional Firecracker VM support).
* IPFS support is ready for encrypted output pinning.
* Node-level slashing/reputation not included in MVP but considered in full protocol.

---

## ğŸ“¬ Contact

Want to collaborate or invest?
**Email:** `decentramind.info@gmail.com`
**Telegram:** `https://t.me/ArmanPayandeh`
**Site:** coming soonâ€¦

---

## Demo

[ğŸ“¹ Screencast.webm](./client-dapp//public/Screencast.webm)

---

Made with â¤ï¸ for the decentralized AI future.
